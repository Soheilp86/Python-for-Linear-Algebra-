{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c2a0dd",
   "metadata": {},
   "source": [
    "# 5. Orthogonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf2baab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6351a93a",
   "metadata": {},
   "source": [
    "## 5.1 Inner product and Orthogonality\n",
    "\n",
    "In this section, we explore inner product and orthogonality. Inner product allows us to define intuitive geometric concepts such as length, distance, and perpendicularity in $n$ dimensional space $\\mathbb{R}^n$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e81d0b",
   "metadata": {},
   "source": [
    "### Inner product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faca33ec",
   "metadata": {},
   "source": [
    "Let $\\vec{u}$ and $\\vec{v}$ be vectors in $\\mathbb{R}^n$. We can view them as $n \\times 1$ matrices. The transpose of $\\vec{u}$, denoted as $\\vec{u}^T$, is a $1\\times n$ matrix. The matrix product of $\\vec{u}^T$ and $\\vec{v}$ yields a $1\\times 1$ matrix, which can be written as a real number (a scalar) without brackets. This scalar is known as the inner product or dot product of $\\vec{u}$ and $\\vec{v}$. To compute it, we multiply the corresponding elements of $\\vec{u}$ and $\\vec{v}$ and sum the results. More precisely, if \n",
    "\n",
    "\n",
    "$$\n",
    "\\vec{u} = \\begin{bmatrix} u_1\\\\ u_2 \\\\ \\vdots \\\\ u_n \\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "\\vec{v} = \\begin{bmatrix} v_1\\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix},\n",
    "$$ \n",
    "\n",
    "then the dot product $\\vec{u} \\cdot \\vec{v}$ is given by:\n",
    "\n",
    "$$\n",
    "\\vec{u} \\cdot \\vec{v} = \\vec{u}^T\\vec{v} = \\begin{bmatrix} u_1 & u_2 & \\dots & u_n \\end{bmatrix} \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix} = u_1v_1 + u_2v_2 + \\dots + u_nv_n\n",
    "$$\n",
    "\n",
    "```{admonition} Example 1\n",
    "\n",
    "Compute $\\vec{u} \\cdot \\vec{v}$ for $\\vec{u} = \\begin{bmatrix} 1\\\\ -1 \\\\ 2 \\end{bmatrix}$ and $\\vec{v} = \\begin{bmatrix} -2 \\\\ 3 \\\\ 4 \\end{bmatrix}$.\n",
    "\n",
    "```\n",
    "\n",
    "__Solution__ \n",
    "\n",
    "We use `numpy.dot()` to compute the dot product in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11774a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "u = np.array([1, -1, 2])\n",
    "v = np.array([-2, 3, 4])\n",
    "\n",
    "uv = np.dot(u,v)\n",
    "uv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85be6ec5",
   "metadata": {},
   "source": [
    "`````{admonition} Theorem 1 (Properties of the dot product)\n",
    ":class: tip\n",
    "\n",
    "Let $\\vec{u}$, $\\vec{v}$ and $\\vec{w}$ be vectors in $\\mathbb{R}^n$, and $c \\in \\mathbb{R}$ be a scalar. Then\n",
    "\n",
    "  1. $\\vec{u}\\cdot\\vec{v} = \\vec{v}\\cdot\\vec{u}.$\n",
    "  \n",
    "  2. $(\\vec{u} + \\vec{v})\\cdot \\vec{w} = \\vec{u}\\cdot\\vec{w} + \\vec{v}\\cdot\\vec{w}.$\n",
    "  \n",
    "  3. $c(\\vec{u}\\cdot\\vec{v}) = (c\\vec{u})\\cdot\\vec{v} = \\vec{u}\\cdot(c\\vec{v}).$\n",
    "  \n",
    "  4. $\\vec{u}\\cdot\\vec{v}\\geq 0$, and $\\vec{u}\\cdot\\vec{u} = 0$ if and only if $\\vec{u}=0.$\n",
    "  \n",
    "`````\n",
    "  \n",
    "  \n",
    "  \n",
    "combining (2) and (3), and using induction we can show:\n",
    "  \n",
    "$$\n",
    "(c_1\\vec{u_1} + c_2\\vec{u}_2 \\dots c_p\\vec{u}_p)\\cdot \\vec{w} = c_1\\vec{w} \\cdot \\vec{u}_1 + c_2\\vec{w} \\cdot \\vec{u}_2 + \\dots c_p\\vec{w} \\cdot \\vec{u}_p\n",
    "$$\n",
    "  \n",
    "  \n",
    "\n",
    "__Length of vectors__\n",
    "\n",
    "Dot product can be used to define the length of vectors: let $\\vec{u}\\in \\mathbb{R}^n$ then the magnitude or the _length_ of $\\vec{u}$, denoted by $\\|\\vec{u}\\|$ is defined by\n",
    "\n",
    "$$\n",
    "\\|\\vec{u}\\| = \\sqrt{\\vec{u} \\cdot \\vec{u}}.\n",
    "$$\n",
    " \n",
    "\n",
    "- Note that this definition of length coincide with the standard notion of length in $\\mathbb{R}^2$ and $\\mathbb{R}^3$.\n",
    "\n",
    "\n",
    "- A vector with a length of $1$ is called as a unit vector. For any vector $\\vec{u}$, there exists a unit vector in the direction of $\\vec{u}$. To obtain this vector, we first calculate the length of $\\vec{u}$ and then divide $\\vec{u}$ by its length $\\|\\vec{u}\\|$. The resulting vector is referred to as the unit vector of $\\vec{u}$, and commonly denoted as $\\vec{e}_u$:\n",
    "\n",
    "$$\n",
    "\\vec{e}_u = \\frac{\\vec{u}}{\\|\\vec{u}\\|}\n",
    "$$\n",
    "\n",
    "This process is often called normalizing a vector, as it transforms $\\vec{u}$ into a unit vector by scaling it to have a length of $1$.\n",
    "\n",
    "```{admonition} Example 2\n",
    "\n",
    "Let $\\vec{u} = \\begin{bmatrix} 1\\\\ 2 \\\\ 3 \\end{bmatrix}$. Compute the following:\n",
    "\n",
    "1. $\\|\\vec{u}\\|$\n",
    "\n",
    "2. $\\|-2\\vec{u}\\|$\n",
    "\n",
    "3. $\\vec{e}_u$\n",
    "\n",
    "```\n",
    "__Solution:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f52f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7416573867739413"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1)\n",
    "\n",
    "u = np.array([1,2,3])\n",
    "\n",
    "uu = np.dot(u,u)\n",
    "\n",
    "length_u = np.sqrt(uu)\n",
    "\n",
    "length_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6504d859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.483314773547883"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2)\n",
    "\n",
    "v = -2*u\n",
    "\n",
    "vv = np.dot(v,v)\n",
    "\n",
    "length_v = np.sqrt(vv)\n",
    "\n",
    "length_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d16227",
   "metadata": {},
   "source": [
    "We could also use the properties of the dot products to compute $\\|-2\\vec{u}\\|$:\n",
    "    \n",
    "$$\\|-2\\vec{u}\\| = \\sqrt{-2\\vec{u}\\cdot -2 \\vec{u}} = 2 (\\vec{u}\\cdot\\vec{u}) = 2 \\|\\vec{u}\\|$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03713c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26726124, 0.53452248, 0.80178373])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(3) comuting the unit vector of u\n",
    "\n",
    "e_u = u/length_u\n",
    "\n",
    "e_u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c91836b",
   "metadata": {},
   "source": [
    "Let's check that the length of $\\vec{e}_u$ is exactly 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73f6b1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_e = np.sqrt(np.dot(e_u,e_u))\n",
    "\n",
    "length_e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a0efe5",
   "metadata": {},
   "source": [
    "```{admonition} Example 3\n",
    "\n",
    "Given vectors \n",
    "\n",
    "$$\n",
    "\\vec{u} = \\begin{bmatrix} 1\\\\ -1 \\\\ 2 \\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "\\vec{v} = \\begin{bmatrix} -2 \\\\ 3 \\\\ 4 \\end{bmatrix},\n",
    "$$\n",
    "\n",
    "and the subspace $W$ spanned by $\\vec{u}$ and $\\vec{v}$, find unit vectors $\\vec{w}_1$ and $\\vec{w}_2$ that form a basis for $W$.\n",
    "```\n",
    "\n",
    "__Solution:__\n",
    "\n",
    "Since $\\vec{u}$ and $\\vec{v}$ are linearly independent (they are not scalar multiples of each other), we can proceed to normalize them to get unit vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c31d6667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_u =  [ 0.40824829 -0.40824829  0.81649658]\n",
      "e_v =  [-0.37139068  0.55708601  0.74278135]\n"
     ]
    }
   ],
   "source": [
    "# unit vector of u\n",
    "u = np.array([1,-1,2])\n",
    "e_u = u / np.sqrt(np.dot(u,u))\n",
    "\n",
    "\n",
    "# unit vector of v\n",
    "v = np.array([-2, 3, 4])\n",
    "e_v = v / np.sqrt(np.dot(v,v))\n",
    "\n",
    "\n",
    "print(\"e_u = \", e_u)\n",
    "print(\"e_v = \", e_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d17ef63",
   "metadata": {},
   "source": [
    "__Distance in $\\mathbb{R}^n$__\n",
    "\n",
    "For $\\vec{u}$ and $\\vec{v}$ in $\\mathbb{R}^n$, the distance between $\\vec{u}$ and $\\vec{v}$, denoted by $\\text{dist}\\ (\\vec{v}, \\vec{u})$, is the length of their difference vector $\\vec{u} - \\vec{v}$. That is,\n",
    "\n",
    "$$\n",
    "\\text{dist}\\ (\\vec{u}, \\vec{v}) = \\|\\vec{u} - \\vec{v}\\|.\n",
    "$$\n",
    "\n",
    "Note that this definition coincide with the standard definition of distances in $\\mathbb{R}^2$ and $\\mathbb{R}^3$.\n",
    "\n",
    "\n",
    "```{admonition} Example 4\n",
    "\n",
    "Compute the distance between vectors in Example 2.\n",
    "```\n",
    "\n",
    "\n",
    "__Solution:__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4019b566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between  [1 2 3]  and  [-2 -4 -6]  is  11.224972160321824\n"
     ]
    }
   ],
   "source": [
    "\n",
    "w = u - v\n",
    "\n",
    "dist = np.sqrt(np.dot(w,w))\n",
    "\n",
    "print(\"The distance between \", u, \" and \", v, \" is \", dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8712dd1",
   "metadata": {},
   "source": [
    "### Angles and Orthogonality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c7d9f",
   "metadata": {},
   "source": [
    "\n",
    "`````{admonition} Theorem 2 (Cauchy-Schwarz inequality)\n",
    ":class: tip\n",
    "\n",
    "For $\\vec{u}$ and $\\vec{v}$ in $\\mathbb{R}^n$ we have \n",
    "\n",
    "$$\n",
    "|\\vec{u}\\cdot\\vec{v}|\\leq \\|\\vec{u}\\|\\|\\vec{v}\\|.\n",
    "$$\n",
    "`````\n",
    "\n",
    "The Cauchy-Schwarz inequality gives us a way to define the notion of angel between two $n$ dimensional vectors $\\vec{u}$ and $\\vec{v}$. This notion also coincide with our intuition in $\\mathbb{R}^2$ and $\\mathbb{R}^3$:\n",
    "\n",
    "Suppose $\\vec{u}, \\vec{v}\\in \\mathbb{R}^n$ are non-zero vectors. Note that \n",
    "\n",
    "$$\n",
    "-1 \\leq \\frac{\\vec{u}\\cdot\\vec{v}}{\\|\\vec{u}\\|\\|\\vec{v}\\|}\\leq 1\n",
    "$$\n",
    "\n",
    "Therefore, there is a unique $\\theta \\in [0,\\pi]$ such that \n",
    "\n",
    "$$\n",
    "\\cos(\\theta) = \\frac{\\vec{u}\\cdot\\vec{v}}{\\|\\vec{u}\\|\\|\\vec{v}\\|}\n",
    "$$\n",
    "\n",
    "$\\theta$ is reffered to as_the angel_ between $\\vec{u}$ and $\\vec{v}$ and is equal to \n",
    "\n",
    "$$\n",
    "\\theta = \\arccos(\\frac{\\vec{u}\\cdot\\vec{v}}{\\|\\vec{u}\\|\\|\\vec{v}\\|})\n",
    "$$\n",
    "\n",
    "\n",
    "```{admonition} Example 5\n",
    "\n",
    "Find the angel between vectors in Example 2.\n",
    "```\n",
    "\n",
    "__Solution:__\n",
    "\n",
    "\n",
    "We first compute the length of $\\vec{u}$ and $\\vec{v}$ and then substitute them in above formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06a7669c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The angel between u and v is  3.141592653589793  rad\n"
     ]
    }
   ],
   "source": [
    "u_len = np.sqrt(np.dot(u,u))\n",
    "v_len = np.sqrt(np.dot(v,v))\n",
    "\n",
    "z = u_len * v_len\n",
    "\n",
    "t = np.arccos(np.dot(u,v)/z)       \n",
    "print(\"The angel between u and v is \", t ,\" rad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8b9d8e",
   "metadata": {},
   "source": [
    "Two vectors $\\vec{u}$ and $\\vec{v}$ are __orthogonal__, denoted by $\\vec{u} \\perp \\vec{v}$, if the angle $\\theta$ between them is $\\frac{\\pi}{2}$. Alternatively, this condition is satisfied if and only if $\\vec{u}\\cdot \\vec{v} = 0$. It is worth noting that the zero vector $\\vec{0}$ is orthogonal to every vector because $\\vec{0}^T \\cdot \\vec{u} = 0$ for any vector $\\vec{u}$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Observe that for any two vectors $\\vec{u}$ and $\\vec{v}$ we have\n",
    "\n",
    "$$\n",
    "\\|\\vec{u}+\\vec{v}\\|^2 = (\\vec{u} + \\vec{v}) \\cdot (\\vec{u} + \\vec{v}) = \\| \\vec{u}\\|^2 + \\| \\vec{v}\\|^2 + 2 \\vec{u}\\cdot \\vec{v}\n",
    "$$\n",
    "\n",
    "The above calculation implies the famous Pythagorean Theorem:\n",
    "\n",
    "`````{admonition} Theorem 3 (The Pythagorean Theorem)\n",
    ":class: tip\n",
    "\n",
    "Two vectors $\\vec{u}$ and $\\vec{v}$ are orthogonal if and only if \n",
    "\n",
    "$$\n",
    "\\|\\vec{u}+\\vec{v}\\|^2 =  \\| \\vec{u}\\|^2 + \\| \\vec{v}\\|^2 \n",
    "$$\n",
    "\n",
    "`````\n",
    "\n",
    "__The orthogonal complement of a subspace__\n",
    "\n",
    "Let $W \\subset \\mathbb{R}^n$ be a subspcae. If a vector $\\vec{u}$ is orthogonal to every vector in the subspace $W$, then $\\vec{u}$ is said to be orthogonal to $W$. The set of all vectors $\\vec{u}$ that are orthogonal to $W$ form a subspace which is commonly called __the orthogonal complement of $W$__ and is denoted by $W^{\\perp}$ (or simply $W^\\perp$):\n",
    "\n",
    "$$\n",
    "W^{\\perp} = \\{\\vec{u}\\in \\mathbb{R}^n: \\vec{u}\\cdot \\vec{w} = 0 \\text{ for all } \\vec{w} \\in W\\}\n",
    "$$\n",
    "\n",
    "```{admonition} Example 6\n",
    "\n",
    "Let $W$ be the $xy$-plane in $\\mathbb{R}^3$, and let $L$ be the $z$-axis. Our intuition says $L$ is orthogonal to $W$. In fact, if $\\vec{z}$ and $\\vec{w}$ are nonzero vectors such that $\\vec{z}\\in L$ and $\\vec{w}\\in W$, then $\\vec{z}$ is orthogonal to $\\vec{w}$. Since $\\vec{w}$ and $\\vec{z}$ were chosen arbitrary, every vector on $L$ is orthogonal to every $\\vec{w}$ in $W$. In fact, $L$ consists of all vectors that are orthogonal to the $\\vec{w}$'s in $W$, and $W$ consists of all vectors $\\vec{w}$ orthogonal to the $\\vec{z}$’s in $L$. Mathematically,\n",
    "\n",
    "$$\n",
    "L = W^{\\perp} \\quad \\text{and} \\quad W = L^{\\perp}\n",
    "$$\n",
    "```\n",
    "\n",
    "```{admonition} Example 7\n",
    "\n",
    "If $W = span\\left\\lbrace \\begin{bmatrix}\n",
    "1\\\\0\\\\0\n",
    "\\end{bmatrix} \\right\\rbrace$, find a basis for $W^{\\perp}$.\n",
    "```\n",
    "\n",
    "__Solution__:\n",
    "\n",
    "Note that $W$ is simply the $x$-axis in $\\mathbb{R}^3$. Intuitively, $W^{\\perp}$ should be the $yz$-plane, and a basis for it is \n",
    "\n",
    "$$\n",
    "B = \\left\\lbrace \\begin{bmatrix}\n",
    "0\\\\1\\\\0\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "0\\\\0\\\\1\n",
    "\\end{bmatrix} \\right\\rbrace.\n",
    "$$\n",
    "\n",
    "Alternatively, we can find the solutions to the linear system:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 0 &0 \n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "x \\\\y \\\\ z\n",
    "\\end{bmatrix} = \\vec{0}.\n",
    "$$\n",
    "\n",
    "We have:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x \\\\y \\\\ z\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "0 \\\\y \\\\ z\n",
    "\\end{bmatrix} = y \\begin{bmatrix}\n",
    "0 \\\\1 \\\\ 0\n",
    "\\end{bmatrix} + z \\begin{bmatrix}\n",
    "0 \\\\0 \\\\ 1\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "\n",
    "We conclude this section with a theorem summarizing the properties of the orthogonal complement of a subspace.\n",
    "\n",
    "`````{admonition} Theorem 4\n",
    ":class: tip\n",
    "\n",
    "Let $W$ be a subspace of $\\mathbb{R}^n$.\n",
    "\n",
    "1. The orthogonal complement $W^{\\perp}$ is also a subspace of $\\mathbb{R}^n$.\n",
    "\n",
    "2. The sum of the dimensions of $W$ and $W^{\\perp}$ is equal to the dimension of the ambient space $\\mathbb{R}^n$, i.e., $dim(W) + dim(W^{\\perp}) = n$.\n",
    "\n",
    "3. If $W$ is the column space of some matrix $A$, i.e., $W = \\text{col}(A)$, then $W^{\\perp}$ is precisely the null space of the transpose of $A$, i.e., $W^{\\perp} = \\text{null}(A^{T})$.\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265d3c3",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e51af08",
   "metadata": {},
   "source": [
    "```{admonition} Exercises\n",
    "\n",
    "1. Let  $ \\vec{a} = \\begin{bmatrix}1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{bmatrix}$. \n",
    "\n",
    "    a. Find a vector $\\vec{w}$ that is in the opposite direction of $\\vec{a}$ and has a magnitude of 2.\n",
    "    \n",
    "    b. Find two non-parallel vectors $\\vec{u}$ and $\\vec{v}$ which are both orthogonal to $\\vec{a}$\n",
    "\n",
    "\n",
    "\n",
    "2. Find two non-parallel vectors $\\vec{u}$ and $\\vec{v}$ which are both orthogonal to $\\begin{bmatrix}\n",
    "1 \\\\ 2 \\\\ 3 \\end{bmatrix}$ and $\\begin{bmatrix} 2 \\\\ -1 \\\\ 0 \\end{bmatrix}.$\n",
    "\n",
    "\n",
    "3. Let \n",
    "\n",
    "$$\n",
    "\\vec{v}= \\begin{bmatrix}\n",
    "1\\\\2\\\\7\n",
    "\\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "and  \n",
    "\n",
    "$$\n",
    "\\vec{w}= \\begin{bmatrix}\n",
    "1\\\\-1\\\\1\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "   a. Find $\\vec{z}= \\vec{v}- \\displaystyle\\left(\\frac{\\vec{v}\\cdot \\vec{w}}{\\vec{w}\\cdot \\vec{w}}\\right)\\vec{w}.$\n",
    "   \n",
    "   b. Check that $\\vec{z}$ is orthogonal to $\\vec{w}.$\n",
    "\n",
    "\n",
    "\n",
    "4. If \n",
    "\n",
    "$$\n",
    "W = span\\left\\lbrace\\ \\begin{bmatrix}\n",
    "1\\\\2\\\\3 \\\\ 4\n",
    "\\end{bmatrix}\\ \\right\\rbrace\n",
    "$$ \n",
    "\n",
    "find a basis for $W^{\\perp}$.\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6e1ab8",
   "metadata": {},
   "source": [
    "## 5. 2 Orthogonal Projection\n",
    "\n",
    "In this section we explore the construction of orthogonal projections which is a key step in many calculations involving orthogonality, and discusses some properties of projection maps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fa507e",
   "metadata": {},
   "source": [
    "### Orthogonal Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970871d0",
   "metadata": {},
   "source": [
    "A set of vectors $\\{\\vec{u}_1, \\vec{u}_2, \\dots, \\vec{u}_p\\}$ in $\\mathbb{R}^{n}$ is called an _orthogonal set_ if each pair of distinct vectors from the set is orthogonal, meaning that $\\vec{u}_i \\cdot \\vec{u}_j = 0$ whenever $i \\neq j$. It is important to note that an orthogonal set, consisting of __nonzero vectors__, is always a linearly independent set. For that reason, if a basis for a subspace $W$ of $\\mathbb{R}^n$ happens to be an orthogonal set, it is called an __orthogonal basis__.\n",
    "\n",
    "\n",
    "In general, an orthogonal basis makes computations easier. The following theorem demonstrates how:\n",
    "\n",
    "`````{admonition} Theorem 5 \n",
    ":class: tip\n",
    "\n",
    "Let \n",
    "\n",
    "$$\n",
    "B = \\{\\vec{u}_1, \\vec{u}_2, \\dots, \\vec{u}_p\\}\n",
    "$$ \n",
    "\n",
    "be an orthogonal basis for a subspace $W\\subset \\mathbb{R}^n$. Moreover, suppose $y\\in W$ can be expressed as a linear combination of the basis elements:\n",
    "\n",
    "$$\n",
    "\\vec{y} = c_1\\vec{u}_1 + c_2\\vec{u}_2 + \\dots + c_p\\vec{u}_p.\n",
    "$$\n",
    "\n",
    "Then the weights $c_i$ are given by\n",
    "\n",
    "$$\n",
    "c_i = \\frac{\\vec{u}_i\\cdot \\vec{y}}{\\vec{u}_i\\cdot \\vec{u}_i} \\quad \\forall i\\in \\{1, 2, \\dots, p\\}.\n",
    "$$\n",
    "`````\n",
    "\n",
    "```{admonition} Example 1 \n",
    "\n",
    "Write the vector \n",
    "\n",
    "$$\n",
    "\\vec{y} = \\begin{bmatrix} 6 \\\\ 1\\\\ -8 \\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "as a linear combination of the vectors in \n",
    "\n",
    "$$\n",
    "S = \\left \\{\\ \\begin{bmatrix} 3 \\\\ 1\\\\ 1 \\end{bmatrix}, \\begin{bmatrix} -1 \\\\ 2\\\\ 1 \\end{bmatrix}, \\begin{bmatrix} -1 \\\\ -4\\\\ 7 \\end{bmatrix}\\ \\right \\}.\n",
    "$$\n",
    "```\n",
    "__Solution:__\n",
    "\n",
    "Since $S$ is an orthogonal set with three nonzero elements, it forms a basis for $\\mathbb{R}^3$. Therefore, we can express $\\vec{y}$ in terms of the vectors in $S$:\n",
    "\n",
    "$$\n",
    "\\vec{y} = c_1 \\begin{bmatrix} 3 \\\\ 1\\\\ 1 \\end{bmatrix} + c_2 \\begin{bmatrix} -1 \\\\ 2\\\\ 1 \\end{bmatrix} + c_3 \\begin{bmatrix} -1 \\\\ -4\\\\ 7 \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "We can solve this vector equation for $c_i$s using techniques we learned in section 1.2. However, Theorem 1 suggests an alternative way for computing the coefficients:\n",
    "\n",
    "$$\n",
    "c_i = \\frac{\\vec{u}_i \\cdot \\vec{y}}{\\vec{u}_i \\cdot \\vec{u}_i} \\quad \\text{for all } i\\in \\{1, 2, 3\\}.\n",
    "$$\n",
    "\n",
    "By substituting the appropriate values of $\\vec{u}_i$ and $\\vec{y}$ into the formula, we can compute the coefficients $c_i$s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49dbf5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 =  1.0 , c2 =  1.0 , c3 =  -1.0\n"
     ]
    }
   ],
   "source": [
    "y = np.array([6, 1, -8])\n",
    "\n",
    "u1 = np.array([3, 1, 1])\n",
    "\n",
    "u2 = np.array([-1, 2, 1])\n",
    "\n",
    "u3 = np.array([-1,-4, 7])\n",
    "\n",
    "#computing the weights:\n",
    "\n",
    "c1 = np.dot(y,u1)/ np.dot(u1,u1)\n",
    "\n",
    "c2 = np.dot(y,u2)/ np.dot(u2,u2)\n",
    "\n",
    "c3 = np.dot(y,u3)/ np.dot(u3,u3)\n",
    "\n",
    "print(\"c1 = \", c1, \", c2 = \", c1, \", c3 = \", c3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c69adb",
   "metadata": {},
   "source": [
    "### Orthogonal Projections onto $1$-dimensional spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6884a9a",
   "metadata": {},
   "source": [
    "Given a nonzero vector $\\vec{y}$ in $\\mathbb{R}^n$, decomposing $\\vec{y}$ into a sum of two vectors is a straightforward task. For example, for any choice of $\\alpha, \\beta \\in \\mathbb{R}$ such that $\\alpha + \\beta = 1$, we have:\n",
    "\n",
    "$$\n",
    "\\vec{y} = \\alpha \\vec{y} + \\beta \\vec{y}.\n",
    "$$\n",
    "\n",
    "A more challenging question is when we want to express $\\vec{y}$ as the sum of two vectors, where one is a scalar multiple of a given vector $\\vec{u}$ and the other is orthogonal to $\\vec{u}$. More perciesely, we seek to write:\n",
    "\n",
    "$$\n",
    "\\vec{y} = \\vec{p} + \\vec{z},\n",
    "$$\n",
    "\n",
    "where $\\vec{p} = \\alpha \\vec{u}$ for some scalar $\\alpha$, and $\\vec{z} \\perp \\vec{p}$. In other words, we are looking for a scalar $\\alpha$ such that $\\vec{z} := \\vec{y} - \\alpha \\vec{u}$ is orthogonal to $\\vec{u}$, which can be expressed as:\n",
    "\n",
    "$$\n",
    "(\\vec{y} - \\alpha \\vec{u}) \\cdot \\vec{u} = 0.\n",
    "$$\n",
    "\n",
    "Simplifying the equation above, we find:\n",
    "\n",
    "$$\n",
    "\\alpha = \\frac{\\vec{y} \\cdot \\vec{u}}{\\vec{u} \\cdot \\vec{u}}, \\quad \\text{and thus} \\quad \\vec{p} = \\frac{\\vec{y} \\cdot \\vec{u}}{\\vec{u} \\cdot \\vec{u}} \\ \\vec{u}, \\quad \\text{and} \\quad \\vec{z} = \\vec{y} - \\vec{p}.\n",
    "$$\n",
    "\n",
    "The vector $\\vec{p}$, sometimes denoted as $\\text{proj}_{\\vec{u}}(\\vec{y})$, is called the __orthogonal projection of $\\vec{y}$ onto $\\vec{u}$__, and $\\vec{z}$ is referred to as the __component of $\\vec{y}$ orthogonal to $\\vec{u}$.__\n",
    "\n",
    "```{admonition} Example 2\n",
    "\n",
    "Suppose \n",
    "\n",
    "$$\n",
    "\\vec{y} = \\begin{bmatrix} 7 \\\\ 6 \\end{bmatrix}$ and $\\vec{u} = \\begin{bmatrix} 4 \\\\ 2 \\end{bmatrix}\n",
    "$$. \n",
    "\n",
    "Compute the $\\text{proj}_{\\vec{u}}(\\vec{y})$ and the component of $\\vec{y}$ orthogonal to $\\vec{u}$ \n",
    "```\n",
    "   \n",
    "__Solution:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3b66d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the projection of y onto u is  [8. 4.]\n",
      "the component of y orthogonal to u is [-1.  2.]\n"
     ]
    }
   ],
   "source": [
    "# setup vectors\n",
    "\n",
    "y = np.array([7,6])\n",
    "\n",
    "u = np.array([4,2])\n",
    "\n",
    "# projection of y onto u\n",
    "\n",
    "proj_y_u = (np.dot(y,u)/ np.dot(u,u))* u\n",
    "print( \"the projection of y onto u is \", proj_y_u) \n",
    "\n",
    "z = y - proj_y_u\n",
    "\n",
    "print(\"the component of y orthogonal to u is\", z )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d31946d",
   "metadata": {},
   "source": [
    "Let's plot $\\text{proj}_{\\vec{u}}(\\vec{y})$ and the component of $\\vec{y}$ orthogonal to $\\vec{u}$  in $xy$-plane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f01f12b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the coordinates in two separate plots\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "figsize=(20, 10)\n",
    "\n",
    "# vector y\n",
    "ax.quiver(0, 0, 7, 6, angles='xy', scale_units='xy', scale=1, color='blue', label ='y')\n",
    "ax.text(7.1,6.1,'$y$')\n",
    "\n",
    "# vector u\n",
    "ax.quiver(0, 0, 4, 2, angles='xy', scale_units='xy', scale=1, color='black')\n",
    "ax.text(4.1,1.6,'$u$')\n",
    "\n",
    "# orthogonal projection p\n",
    "ax.quiver(0, 0, 8, 4, angles='xy', scale_units='xy', scale=1, color='red')\n",
    "ax.text(8.1,4.1,'$p$')\n",
    "\n",
    "# vector z\n",
    "ax.quiver(0, 0, -1, 2, angles='xy', scale_units='xy', scale=1, color='green')\n",
    "ax.text(-1.1,2.2,'$z = y - p$')\n",
    "\n",
    "# A copy of vector z starting at the end of vector p\n",
    "ax.quiver(8, 4, -1, 2, angles='xy', scale_units='xy', scale=1, color='green')\n",
    "\n",
    "\n",
    "\n",
    "ax.set_xlim([-4, 10])\n",
    "ax.set_ylim([-4, 10])\n",
    "ax.set_aspect('equal')\n",
    "ax.axhline(y=0, color='black', linestyle='--', linewidth=0.5)\n",
    "ax.axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "ax.set_title('y = p + z')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac969cc",
   "metadata": {},
   "source": [
    "### Orthogonal Projections onto a general subspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414c0bdf",
   "metadata": {},
   "source": [
    "Let's take another look the above Figure from Example 2. The projection of $\\vec{y}$ onto any vector in the direction of $\\vec{u}$, results in the same vector $\\text{proj}_{\\vec{u}}(\\vec{y})$. In fact, what matters to us is the line that contains $\\vec{u}$ (span$(\\{\\vec{u}\\})$). With this in mind, we can interpret $\\text{proj}_{\\vec{u}}(\\vec{y})$ as the projection of $\\vec{y}$ onto a subspace of $\\mathbb{R}^n$ generated by $\\vec{u}$, and we can write it as $\\text{proj}_{\\text{span}(L)}(\\vec{y})$. In fact, the notion of projection can be generalized to any subspace of $\\mathbb{R}^n$.\n",
    "\n",
    "\n",
    "\n",
    "`````{admonition} Theorem 6\n",
    ":class: tip\n",
    "\n",
    "Let $W$ be a subspace of $\\mathbb{R}^n$. Then each $\\vec{y}\\in \\mathbb{R}^n$ can be written uniquely as\n",
    "\n",
    "$$\n",
    "\\vec{y} = \\vec{p} + \\vec{z}\n",
    "$$\n",
    "\n",
    "where $\\vec{p}$ is in $W$ and $\\vec{z}$ is in $W^{\\perp}$. Moreover, if $B = \\{\\vec{u}_1, \\vec{u}_2, \\dots \\vec{u}_p\\}$ is any orthogonal basis of $W$, then\n",
    "\n",
    "$$\n",
    "\\vec{p} =  \\frac{\\vec{y}\\cdot \\vec{u}_1}{\\vec{u}_1\\cdot \\vec{u}_1} + \\frac{\\vec{y}\\cdot \\vec{u}_2}{\\vec{u}_2\\cdot \\vec{u}_2} + \\dots + \\frac{\\vec{y}\\cdot \\vec{u}_p}{\\vec{u}_p\\cdot \\vec{u}_p} \\quad  (**) \\quad \\text{and} \\quad \\vec{z} = \\vec{y} - \\vec{p} \n",
    "$$\n",
    "\n",
    "`````\n",
    "\n",
    "The vector $\\vec{p}$, sometimes denoted by $\\text{proj}_{W}(\\vec{y})$ is called the __orthogonal projection__ of $\\vec{y}$ onto $W$, and $\\vec{z}$ is called the component of $\\vec{y}$ orthogonal to $W$. \n",
    "\n",
    "```{admonition} Example 3\n",
    "\n",
    "Suppose \n",
    "\n",
    "$$\n",
    "\\vec{u} _1 = \\begin{bmatrix} 2 \\\\ 5 \\\\ -1 \\end{bmatrix},\n",
    "$$\n",
    "\n",
    "$$\\vec{u}_2 = \\begin{bmatrix} -2 \\\\ 1 \\\\ 1 \\end{bmatrix},\n",
    "$$, \n",
    "\n",
    "$W = \\text{span} (\\vec{u}_1, \\vec{u}_2)$ and \n",
    "\n",
    "$$\n",
    "\\vec{y} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Compute the $\\text{proj}_{W}(\\vec{y})$ and the component of $\\vec{y}$ orthogonal to $\\vec{u}.$ \n",
    "```\n",
    "   \n",
    "__Solution:__ \n",
    "\n",
    "$\\vec{u}_1$ and $\\vec{u}_2$ are orthogonal and form a basis for $W$; thus, we can use Theorem 3 to compute the projection of $\\vec{y}$ onto $W$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2f540cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The projection of y onto W is  [-0.4  2.   0.2] \n",
      "\n",
      "The component of y orthogonal to u is [1.4 0.  2.8]\n"
     ]
    }
   ],
   "source": [
    "# setup vectors\n",
    "\n",
    "u1 = np.array([2,5,-1])\n",
    "\n",
    "u2 = np.array([-2,1,1])\n",
    "\n",
    "y = np.array([1,2,3])\n",
    "\n",
    "# projection of y onto W\n",
    "\n",
    "proj_y_W = (np.dot(y,u1)/ np.dot(u1,u1))* u1  +  (np.dot(y,u2)/ np.dot(u2,u2))* u2\n",
    "\n",
    "print( \"The projection of y onto W is \", proj_y_W, '\\n') \n",
    "\n",
    "# component of y orthogonal to p\n",
    "z = y - proj_y_W\n",
    "\n",
    "print(\"The component of y orthogonal to u is\", z )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447e2e23",
   "metadata": {},
   "source": [
    "Note that if $\\vec{y}$ happens to be in $W$ then $\\text{proj}_{W}(\\vec{y}) = \\vec{y}$. We can verify this fact for $\\vec{u}_1$ which we know belongs to $W$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "080dedb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  5. -1.]\n"
     ]
    }
   ],
   "source": [
    "proj_u_W = (np.dot(u1,u1)/ np.dot(u1,u1))* u1  +  (np.dot(u1,u2)/ np.dot(u2,u2))* u2\n",
    "print(proj_u_W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9d5db6",
   "metadata": {},
   "source": [
    "### The Best Approximation Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51448e8d",
   "metadata": {},
   "source": [
    "Projections can be viewed as linear transformations:\n",
    "\n",
    "Consider a subspace $W$ of $\\mathbb{R}^n$, and let $T_W: \\mathbb{R}^{n} \\to W$ be the mapping that sends a vector $\\vec{y}$ to its orthogonal projection $\\text{proj}_{W}(\\vec{y})$. It is known that $T_W$ is a linear transformation. If $P$ represents the matrix of $T_W$, then $P^2 = P$. More precisely,\n",
    "\n",
    "$$\n",
    "P\\vec{w} \\in W \\quad \\forall \\vec{w}\\in W\n",
    "$$\n",
    "\n",
    "Informally, we say $P$ does not move elements of $W$. The following theorem states that if $\\vec{u}$ is not in $W$, then $P$ sends it to _the closest point_ in $W$ from $\\vec{u}$.\n",
    "\n",
    "`````{admonition} Theorem 7 (The Best Approximation Theorem)\n",
    "\n",
    "Let $W$ be a subspace of $\\mathbb{R}^2$, and let $\\vec{y}\\in \\mathbb{R}^n$. The projection of $\\vec{y}$ onto $W$, denoted as $\\vec{p} = \\text{proj}_{W}(\\vec{y})$, is the closest point in $W$ to $\\vec{y}$ in the following sense:\n",
    "\n",
    "$$\n",
    "\\| \\vec{y}-\\vec{p}\\| \\leq \\|\\vec{y}-\\vec{w}\\| \\quad \\forall \\vec{w} \\in W\n",
    "$$\n",
    "\n",
    "In particular, if $\\vec{y}\\in W$, then the closest point is exactly $\\vec{y}$. We refer to $\\vec{p}$ as the best approximation to $\\vec{y}$ by elements of $W$. The real number $\\| \\vec{y}-\\vec{p}\\|$) is interpreted as the distance between the vector $\\vec{y}$ and the subspace $W$.\n",
    "`````\n",
    "\n",
    "```{admonition} Example 4 \n",
    "\n",
    "Suppose \n",
    "\n",
    "$$\n",
    "\\vec{y} = \\begin{bmatrix} -1 \\\\ -5 \\\\ 10 \\end{bmatrix},\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\vec{u}_2 = \\begin{bmatrix} 5 \\\\ -2 \\\\ 1 \\end{bmatrix},\n",
    "$$\n",
    "\n",
    "$W = \\text{span} (\\vec{u}_1, \\vec{u}_2)$ \n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "\\vec{y} = \\begin{bmatrix} 1 \\\\ 2 \\\\ -1\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "   1. What is the closest point to $\\vec{y}$ in $W$?\n",
    "\n",
    "   2. Find the distance between $\\vec{y}$ and $W$.\n",
    "```\n",
    "\n",
    "__Solution__ \n",
    "\n",
    "1. The closes point is the projection of $\\vec{y}$ onto $W$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2166063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The projection of y onto W is  [-1. -8.  4.] \n",
      "\n",
      "The component of y orthogonal to u is [0. 3. 6.] \n",
      "\n",
      "The distance between y and $W$ is 6.708203932499369\n"
     ]
    }
   ],
   "source": [
    "# setup vectors\n",
    "\n",
    "y = np.array([-1, -5, 10])\n",
    "\n",
    "u1 = np.array([5, -2, 1])\n",
    "\n",
    "u2 = np.array([1 , 2, -1])\n",
    "\n",
    "# projection of y onto W\n",
    "\n",
    "p = (np.dot(y,u1)/ np.dot(u1,u1))* u1  +  (np.dot(y,u2)/ np.dot(u2,u2))* u2\n",
    "\n",
    "print( \"The projection of y onto W is \", p, '\\n') \n",
    "\n",
    "\n",
    "# component of y orthogonal to p\n",
    "z = y - p\n",
    "\n",
    "print(\"The component of y orthogonal to u is\", z, '\\n' )\n",
    "\n",
    "# distance between y and W\n",
    "r = np.sqrt(np.dot(z,z))\n",
    "print(\"The distance between y and $W$ is\", r )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d2255",
   "metadata": {},
   "source": [
    "It is possible to simplify the $(**)$ formula in Theorem 6 that computes projection. First we need the following definition:\n",
    "\n",
    "A basis $B$ for a subspace $W$ is called an __orthonormal basis__ if $B$ is an orthogonal basis and every element of $B$ is a unit vector. Any orthogonal basis can be turned into an orthonormal basis by normalizing every basis elements.\n",
    "\n",
    "`````{admonition} Theorem 8\n",
    ":class: tip\n",
    "\n",
    "Let $W$ be a subspace of $\\mathbb{R}^n$ and $B = \\{\\vec{u}_1, \\vec{u}_2, \\dots \\vec{u}_p\\}$ be an orthonormal basis of $W$. Then, foe every $\\vec{y}\\in \\mathbb{R}^n$, the projection of $\\vec{y}$ onto $W$ is\n",
    "\n",
    "$$\n",
    "\\text{proj}_{W}(\\vec{y}) = \\vec{y}\\cdot\\vec{u_1} + \\vec{y}\\cdot\\vec{u_2} + \\dots + \\vec{y}\\cdot\\vec{u_p}\n",
    "$$\n",
    "`````\n",
    "\n",
    "We can also represent this formula even in a more compact form:\n",
    "\n",
    "if $U = \\left[ \\vec{u}_1, \\vec{u_2}, \\dots, \\vec{u}_p \\right]$ then \n",
    "\n",
    "$$\n",
    "\\text{proj}_{W}(\\vec{y}) = UU^{T} \\vec{y} \\quad (*)\n",
    "$$\n",
    "\n",
    "\n",
    "A matrix whose columns are orthonormal, such as $U$, is called orthogonal matrix. For an $n\\times n$ orthogonal matrix $U$, beside (*), we have \n",
    "\n",
    "$$\n",
    "U^TU = I_n \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9d7c2f",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd304db",
   "metadata": {},
   "source": [
    "```{admonition} Exercises\n",
    "\n",
    "1. Let \n",
    "\n",
    "$$\n",
    "\\cal{B}=\\left\\lbrace \\begin{bmatrix}\n",
    "1 \\\\ 1\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "1 \\\\ -1\n",
    "\\end{bmatrix} \\right\\rbrace\n",
    "$$ \n",
    "\n",
    "be a basis of $\\mathbb{R}^2.$\n",
    "\n",
    "   a. Check that this is an orthogonal basis.\n",
    "   \n",
    "   b. Find the coordinates of the vector \n",
    "   \n",
    "   $$\n",
    "   \\begin{bmatrix}\n",
    "3 \\\\ 5\n",
    "\\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "with respect to the basis $\\cal{B}$\n",
    "\n",
    "\n",
    "\n",
    "2. Suppose \n",
    "\n",
    "$$\n",
    "\\vec{u}_1 = \\begin{bmatrix} -7 \\\\ 1 \\\\ 4 \\end{bmatrix},\n",
    "$$ \n",
    "\n",
    "$$\n",
    "\\vec{u}_2 = \\begin{bmatrix} -1 \\\\ 1 \\\\ -2 \\end{bmatrix},\n",
    "$$\n",
    "\n",
    "$W = \\text{span} (\\vec{u}_1, \\vec{u}_2)$ and \n",
    "\n",
    "$$\n",
    "\\vec{y} = \\begin{bmatrix} -9 \\\\ 1 \\\\ 6\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "    a. Show that $\\vec{u}_1$ and $\\vec{u}_2$ are orthogonal.\n",
    "    \n",
    "    b. What is the closest points to $\\vec{y}$ in $W$.    \n",
    "    \n",
    "    c. Find the distance between $W$ and $\\vec{y}$.\n",
    "    \n",
    "    d. Convert $\\{\\vec{u}_1, \\vec{u}_2\\}$ into an orthonormal basis for $W$.\n",
    "    \n",
    "    e. Compute the projection of $\\vec{y}$ onto $W$ using the $(*)$ formula given in Theorem 4.\n",
    "    \n",
    "    f. Write $\\vec{y}$ as sum of two vectors one in $W$ and the other in $W^{\\perp}$.\n",
    "    \n",
    "    ```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2e23a3",
   "metadata": {},
   "source": [
    "## 5. 3 The Gram–Schmidt Process\n",
    "\n",
    "In the previous sections we saw the importance of working with an orthogonal and orthonormal bases. In this section, we explore _the Gram–Schmidt process_ which is a simple algorithm to construct an orthogonal or orthonormal basis from any nonzero subspace of $\\mathbb{R}^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0eef1c",
   "metadata": {},
   "source": [
    "### Idea: construction of an orthogonal basis form a basis with two elements \n",
    "\n",
    "To see the idea behind the Gram–Schmidt process let's review Example 2 in Section 5.2:\n",
    "\n",
    "Suppose $\\vec{y} = \\begin{bmatrix} 7 \\\\ 6 \\end{bmatrix}$ and $\\vec{u} = \\begin{bmatrix} 4 \\\\ 2 \\end{bmatrix}$. $\\vec{y}$ and $\\vec{u}$ are linearly independent and form a basis for $\\mathbb{R}^2$. Clearly, as shown in below figure, $\\vec{y}$ and $\\vec{u}$ are not orthogonal, however $\\vec{y}$ and $\\vec{z}$ (the component of $\\vec{y}$ orthogonal to $\\vec{u}$) form an orthogonal basis for $\\mathbb{R}^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9eb6f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The projection of y onto u is  [8. 4.]\n",
      "The component of y orthogonal to u is [-1.  2.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setup vectors\n",
    "\n",
    "y = np.array([7,6])\n",
    "\n",
    "u = np.array([4,2])\n",
    "\n",
    "# projection of y onto u\n",
    "\n",
    "proj_y_u = (np.dot(y,u)/ np.dot(u,u))* u\n",
    "print( \"The projection of y onto u is \", proj_y_u) \n",
    "\n",
    "z = y - proj_y_u\n",
    "\n",
    "print(\"The component of y orthogonal to u is\", z )\n",
    "\n",
    "\n",
    "# Plot the coordinates in two separate plots\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "figsize=(10, 5)\n",
    "\n",
    "# vector y\n",
    "ax.quiver(0, 0, 7, 6, angles='xy', scale_units='xy', scale=1, color='blue', label ='y')\n",
    "ax.text(7.1,6.1,'$y$')\n",
    "\n",
    "# vector u\n",
    "ax.quiver(0, 0, 4, 2, angles='xy', scale_units='xy', scale=1, color='black')\n",
    "ax.text(4.1,1.6,'$u$')\n",
    "\n",
    "# orthogonal projection p\n",
    "ax.quiver(0, 0, 8, 4, angles='xy', scale_units='xy', scale=1, color='red')\n",
    "ax.text(8.1,4.1,'$p$')\n",
    "\n",
    "# vector z\n",
    "ax.quiver(0, 0, -1, 2, angles='xy', scale_units='xy', scale=1, color='green')\n",
    "ax.text(-1.1,2.2,'$z = y - p$')\n",
    "\n",
    "# A copy of vector z starting at the end of vector p\n",
    "ax.quiver(8, 4, -1, 2, angles='xy', scale_units='xy', scale=1, color='green')\n",
    "\n",
    "\n",
    "\n",
    "ax.set_xlim([-4, 10])\n",
    "ax.set_ylim([-4, 10])\n",
    "ax.set_aspect('equal')\n",
    "ax.axhline(y=0, color='black', linestyle='--', linewidth=0.5)\n",
    "ax.axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "ax.set_title('y = p + z')\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82332d40",
   "metadata": {},
   "source": [
    "Therefore, we have converted a basis for $\\mathbb{R}^2$ into an orthogonal basis for $\\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a28d8f",
   "metadata": {},
   "source": [
    "### Construction of an orthogonal basis form a basis with three elements "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd235116",
   "metadata": {},
   "source": [
    "```{admonition} Example 1\n",
    "\n",
    "Let \n",
    "\n",
    "$$\n",
    "\\vec{x}_1 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1\\\\ 1 \\end{bmatrix},\n",
    "$$, \n",
    "\n",
    "$$\\vec{x}_2 = \\begin{bmatrix} 0 \\\\ 1 \\\\ 1\\\\ 1 \\end{bmatrix}$$, \n",
    "\n",
    "$$\\vec{x}_3 = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1\\\\ 1 \\end{bmatrix}$$, and \n",
    "\n",
    "$$W = \\text{span}(\\{\\vec{x}_1, \\vec{x}_2, \\vec{x}_3\\})$$. \n",
    "\n",
    "Construct an orthogonal basis for $W$.\n",
    "\n",
    "\n",
    "```\n",
    "__Solution:__\n",
    "\n",
    "The set $\\{\\vec{x}_1, \\vec{x}_2, \\vec{x}_3\\}$ is a linearly independent and forms a basis for $W$. We will construct an orthogonal set of vectors $\\{\\vec{v}_1, \\vec{v}_2, \\vec{v}_3\\}$ such that $W = \\text{span}(\\{\\vec{v}_1, \\vec{v}_2, \\vec{v}_3\\})$.\n",
    "\n",
    "__Step 1:__ \n",
    "\n",
    "Define $\\vec{v}_1 := \\vec{x}_1$ and $W_1 := \\text{span}(\\vec{v}_1)$.\n",
    "\n",
    "__Step 2:__ We seek a vector $\\vec{v_2}$ orthogonal to $\\vec{v_1}$. Project $\\vec{x}_2$ onto $W_1$; the component of $\\vec{x}_2$ orthogonal to the subspace $W_1$ has the desired property:\n",
    "\n",
    "$$\\vec{v}_2 = \\vec{x}_2 - \\text{proj}_{W_1}^{\\vec{x}_2}\\quad \\implies \\vec{v_2} \\quad \\perp \\vec{v_1}$$\n",
    "\n",
    "Now, let $W_2 = \\text{span}(\\vec{v}_1, \\vec{v}_2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2db71c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The projection of x2 onto x1 is  [0.75 0.75 0.75 0.75] \n",
      "\n",
      "The component of x1 orthogonal to W1 is [-0.75  0.25  0.25  0.25]\n"
     ]
    }
   ],
   "source": [
    "# setup vectors\n",
    "\n",
    "x1 = np.array([1,1,1,1])\n",
    "\n",
    "x2 = np.array([0,1,1,1])\n",
    "\n",
    "x3 = np.array([0,0,1,1])\n",
    "\n",
    "v1 = x1\n",
    "# projection of x2 onto x1\n",
    "\n",
    "proj_x2_v1 = (np.dot(x2,v1)/ np.dot(v1,v1))* v1\n",
    "print( \"The projection of x2 onto x1 is \", proj_x2_v1, '\\n') \n",
    "\n",
    "v2 = x2 - proj_x2_v1\n",
    "\n",
    "print(\"The component of x1 orthogonal to W1 is\", v2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25515320",
   "metadata": {},
   "source": [
    "__Step 3:__\n",
    "\n",
    "We can use a similar approach to construct $\\vec{v}_3$. We find the orthogonal projection of $\\vec{x}_3$ onto $W_2$ and define $\\vec{v}_3$ as the component of $\\vec{x}_3$ that is orthogonal to the subspace $W_2$:\n",
    "\n",
    "$$\n",
    "\\vec{v}_3 = \\vec{x}_3 - \\text{proj}_{W_2}(\\vec{x}_3)\n",
    "$$\n",
    "\n",
    "Since both $\\vec{x}_3$ and $\\text{proj}_{W_2}(\\vec{x}_3)$ are elements of $W$, $\\vec{v}_3$ is also in $W$. Moreover, by definition, $\\vec{v}_3$ is orthogonal to both $\\vec{v}_1$ and $\\vec{v}_2$. Thus, $\\{\\vec{v}_1, \\vec{v}_2, \\vec{v}_3\\}$ forms an orthogonal basis for $W$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce82b872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the projection of x3 onto W2 is  [0.         0.66666667 0.66666667 0.66666667] \n",
      "\n",
      "the component of x3 orthogonal to W2 is [ 0.         -0.66666667  0.33333333  0.33333333]\n"
     ]
    }
   ],
   "source": [
    "# projection of x3 onto W2\n",
    "\n",
    "proj_x3_W2 = (np.dot(x3,v1)/ np.dot(v1,v1))* v1  +  (np.dot(x3,v2)/ np.dot(v2,v2))* v2\n",
    "\n",
    "print( \"the projection of x3 onto W2 is \", proj_x3_W2, '\\n') \n",
    "\n",
    "# component of y orthogonal to p\n",
    "v3 = x3 - proj_x3_W2\n",
    "\n",
    "print(\"the component of x3 orthogonal to W2 is\", v3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087c993",
   "metadata": {},
   "source": [
    "\n",
    "__Step 4 (Optional)__  \n",
    "\n",
    "Normalizing the basis elements $\\vec{v_1}$, $\\vec{v_2}$, and $\\vec{v_3}$, we will get unit vectors $\\vec{e_1}$, $\\vec{e_2}$, and $\\vec{e_3}$ respectievely. $\\{\\vec{e_1}, \\vec{e_2}, \\vec{e_3}\\}$ is an orthonormal basis for $W$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d853c547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1 =  [0.5 0.5 0.5 0.5]\n",
      "e2 =  [-0.8660254   0.28867513  0.28867513  0.28867513]\n",
      "e3 =  [ 0.         -0.81649658  0.40824829  0.40824829]\n"
     ]
    }
   ],
   "source": [
    "# The unit vector of v1\n",
    "e1 = v1 / np.sqrt(np.dot(v1,v1))\n",
    "\n",
    "# The unit vector of v1\n",
    "e2 = v2 / np.sqrt(np.dot(v2,v2))\n",
    "\n",
    "# The unit vector of v1\n",
    "e3 = v3 / np.sqrt(np.dot(v3,v3))\n",
    "\n",
    "print(\"e1 = \", e1)\n",
    "print(\"e2 = \", e2)\n",
    "print(\"e3 = \", e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6ff18a",
   "metadata": {},
   "source": [
    "### The Gram_Schmidt Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a8c18e",
   "metadata": {},
   "source": [
    "`````{admonition} Theorem 8 (the Gram-Schmidt algorithm)\n",
    ":class: tip\n",
    "\n",
    "Let $W \\subset \\mathbb{R}^n$ be a non-zero subspace, and $\\{\\vec{x_1}, \\vec{x_2}, \\dots, \\vec{x_p}\\}$ be a basis for $W$. Define:\n",
    "\n",
    "\\begin{align}\n",
    "\\vec{v_1} &= \\vec{x_1} \\quad \\text{and} \\quad W_1 = \\text{span}(\\vec{v_1}),\\\\\n",
    "\\vec{v_2} &= \\vec{x_2} - \\text{proj}_{W_1}(\\vec{x_2}) \\quad \\text{and} \\quad W_2 = \\text{span}(\\{\\vec{v_1}, \\vec{v_2}\\}),\\\\\n",
    "& \\vdots \\\\\n",
    "\\vec{v_p} &= \\vec{x_p} - \\text{proj}_{W_{p-1}}(\\vec{x_p}) \\quad \\text{and} \\quad W_p = \\text{span}(\\{\\vec{v_1}, \\vec{v_2}, \\dots, \\vec{v_3}\\}).\n",
    "\\end{align}\n",
    "\n",
    "Then $W = W_p$, and $\\{\\vec{v_1}, \\vec{v_2}, \\dots, \\vec{v_p}\\}$ is an orthogonal basis for $W$. Moreover, if $\\vec{e_1}, \\vec{e_2}, \\dots, \\vec{e_p}$ are the unit vectors of $\\vec{v_1}, \\vec{v_2}, \\dots, \\vec{v_p}$ respectively, then $\\{\\vec{e_1}, \\vec{e_2}, \\dots, \\vec{e_p}\\}$ is an orthonormal basis for $W$.\n",
    "`````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abc6a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup A\n",
    "A = np.transpose([x1, x2, x3])\n",
    "\n",
    "# setup Q\n",
    "Q = np.transpose([e1, e2, e3])\n",
    "\n",
    "# Compute R= Q^T*A\n",
    "R = np.transpose(Q) @ A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89a586ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.00000000e+00, 1.50000000e+00, 1.00000000e+00],\n",
       "       [1.11022302e-16, 8.66025404e-01, 5.77350269e-01],\n",
       "       [1.11022302e-16, 1.11022302e-16, 8.16496581e-01]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb5beb5",
   "metadata": {},
   "source": [
    "Note that elements below the diagonal in $R$ are very small and close to zero. In fact, $R$ should be an upper triangular matrix. The reason why Python won't display the exact decimal numbers we expect is that some decimal fractions cannot be represented exactly as binary fractions. To address this issue, we can set very small elements of $R$ to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07c2de28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.        , 1.5       , 1.        ],\n",
       "       [0.        , 0.8660254 , 0.57735027],\n",
       "       [0.        , 0.        , 0.81649658]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 0.000001 \n",
    "R[np.abs(R) < eps] = 0\n",
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb4ee13",
   "metadata": {},
   "source": [
    "__Numerical Note__ \n",
    "\n",
    "When the Gram–Schmidt process is run on a computer, round off error can build up as the vectors $\\vec{v_k}$ are calculated, one by one. Specifically, for large and unequal values of $k$ and $j$, the dot products $\\vec{v_k}^T \\cdot \\vec{u_j}$ may not be sufficiently close to zero, leading to a loss of orthogonality. This loss of orthogonality can be reduced substantially by rearranging the order of the calculations. \n",
    "\n",
    "\n",
    "We can also utilize `numpy.linalg.qr` in Python to compute the QR factorization of a matrix. This function provides an efficient and accurate implementation of the Gram-Schmidt process avoiding unnecessary loss of orthogonality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d036e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q = \n",
      " [[-0.5         0.8660254   0.        ]\n",
      " [-0.5        -0.28867513  0.81649658]\n",
      " [-0.5        -0.28867513 -0.40824829]\n",
      " [-0.5        -0.28867513 -0.40824829]] \n",
      "\n",
      "\n",
      "R = \n",
      " [[-2.         -1.5        -1.        ]\n",
      " [ 0.         -0.8660254  -0.57735027]\n",
      " [ 0.          0.         -0.81649658]]\n"
     ]
    }
   ],
   "source": [
    "Q, R = np.linalg.qr(A)\n",
    "\n",
    "print('Q = \\n', Q, '\\n\\n')\n",
    "\n",
    "print('R = \\n', R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318464e9",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb02005",
   "metadata": {},
   "source": [
    "```{admonition} Exercises\n",
    "\n",
    "1. Let \n",
    "\n",
    "$$\n",
    "\\vec{x}_1 = \\begin{bmatrix} 3 \\\\ 1 \\\\ -1\\\\ 3 \\end{bmatrix},\n",
    "$$,\n",
    "\n",
    "$$\n",
    "\\vec{x}_2 = \\begin{bmatrix} -5 \\\\ 1 \\\\ 5\\\\ -7 \\end{bmatrix},\n",
    "$$, \n",
    "\n",
    "$$\n",
    "\\vec{x}_3 = \\begin{bmatrix} 1\\\\ 1 \\\\ -2\\\\ 8 \\end{bmatrix},\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "W = \\text{span}(\\{\\vec{x}_1, \\vec{x}_2, \\vec{x}_3\\}).\n",
    "$$\n",
    "\n",
    "Construct an orthonormal basis for $W$.\n",
    "\n",
    "\n",
    "2. Let $A$ be a matrix whose columns are $\\vec{x}_1$, $\\vec{x}_2$, $\\vec{x}_3$ from Exercise 1:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix} 3 & -5 & 1 \\\\  1 & 1 & 1 \\\\ -1 & 5 & -2 \\\\ 3 & -7 & 8\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Find a QR decomposition for $A$.\n",
    "\n",
    "\n",
    "3. Let $A = QR$, where $Q$ is an $m \\times n$ matrix with orthogonal columns, and $R$ is an $n \\times n$ matrix. Show that if the columns of $A$ are linearly dependent, then $R$ cannot be invertible.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb96fd8",
   "metadata": {},
   "source": [
    "## 5.4 Least-Squares Problems\n",
    "\n",
    "Linear systems arising in applications are often inconsistent. In such situations, the best one can do is to find a vector $\\vec{x}'$ that makes $A\\vec{x}$ as close as possible to $\\vec{b}$. We think of $A\\vec{x}$ as an approximation of $\\vec{b}$. The smaller $\\|\\vec{b} - A\\vec{x}\\|$, the better the approximation. Therefore, we are looking for a vector $\\hat{y}$ such that $\\|\\vec{b} - A\\hat{x}\\|$ is as small as possible. Such $\\vec{y}$ is called the _least square solution_ of $A\\vec{x} = \\vec{b}$. The name is motivated by the fact that $\\|\\vec{b} - A\\hat{x}\\|$ is the square root of a sum of squares. In this section we explore this idea further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad2039c",
   "metadata": {},
   "source": [
    "Let $A\\vec{x} = \\vec{b}$ be inconsistent, which implies $\\vec{b}\\notin \\text{col}(A)$. Note that no matter what $\\vec{x}$ is, $A\\vec{x}$ lies in $\\text{col}(A)$. From Section 5.2, we know that the closest point to $\\vec{b}$ in $\\text{col}(A)$ is the projection of $\\vec{b}$ onto $\\text{col}(A)$ (the best approximation problem). Let $\\hat{b} = \\text{proj}_{\\text{col}(A)}(\\vec{b})$. Since $A\\vec{x} = \\hat{b}$ is consistent, there are $\\hat{x}$ such that $A\\hat{x} = \\hat{b}$. $\\hat{x}$ is a least square solution of $A\\vec{x} = \\vec{b}$. Recall that $\\vec{b} -\\hat{b}$ is orthogonal to $\\text{col}(A)$, and thus so is $\\vec{b} - A\\hat{x}$. In other words, $\\vec{b} - A\\hat{x}$ is orthogonal to each column of $A$, and we have:\n",
    "\n",
    "$$\n",
    "A^{T}(\\vec{b} - A\\hat{x}) = 0 \\quad \\text{or} \\quad A^{T}A\\vec{x}= A^{T}\\vec{b}.\n",
    "$$\n",
    "\n",
    "The equation $A^{T}A\\vec{x}= A^{T}\\vec{b}$ is called the __normal equation__ for $A\\vec{x} = \\vec{b}$.\n",
    "\n",
    "`````{admonition} Theorem 9\n",
    "\n",
    "The set of least-squares solutions of $A\\vec{x} = \\vec{b}$ coincides with the nonempty set of solutions of the normal equation $A^{T}A\\vec{x}= A^{T}\\vec{b}$.\n",
    "\n",
    "\n",
    "`````\n",
    "\n",
    "```{admonition} Example 1\n",
    "\n",
    "Find a least-squares solution of the inconsistent system $A\\vec{x} = \\vec{b}$ for \n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix} 4 & 2\\\\ 0 & 2 \\\\ 1 & 1 \\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "\\vec{b} = \\begin{bmatrix} 2 \\\\0 \\\\11 \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "__Solution:__ First, let's find $A^TA$ and $A^T\\vec{b}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "313819f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A^TA = \n",
      " [[17  1]\n",
      " [ 1  5]]\n",
      "\n",
      " A^Tb = \n",
      " [[19]\n",
      " [11]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[4,0], [0,2], [1,1]])\n",
    "\n",
    "b = np.array([[2], [0], [11]])\n",
    "\n",
    "# compute A^TA\n",
    "ATA = A.transpose() @ A \n",
    "\n",
    "print(\"A^TA = \\n\", ATA)\n",
    "\n",
    "# compute A^Tb\n",
    "ATb = A.transpose() @ b \n",
    "\n",
    "print(\"\\n A^Tb = \\n\", ATb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e26764",
   "metadata": {},
   "source": [
    "Thus, the normal equation for $A\\vec{x} = \\vec{b}$ is given by:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 17 & 1 \\\\ 1 & 5 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 19 \\\\ 11 \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "To solve this equation, we can use row operations; alternatively, since $A^TA$ is invertible and $2 \\times 2$, we can use the invertible matrix theorem. In many calculations, $A^TA$ is invertible, but this is not always the case. In Theorem 2, we will see when this is true. The least square solution $\\hat{x}$ is given by:\n",
    "\n",
    "$$\n",
    "\\hat{x} = (A^TA)^{-1} A^{T}\\vec{b}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57aecfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [2.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing x_hat\n",
    "\n",
    "x_hat = np.linalg.inv(ATA) @ ATb\n",
    "x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a6faee",
   "metadata": {},
   "source": [
    "```{admonition} Example 2 \n",
    "\n",
    "Find a least-squares solution of the inconsistent system \n",
    "\n",
    "$$\n",
    "A\\vec{x} = \\vec{b}\n",
    "$$ \n",
    "\n",
    "for \n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix} 1 & 1 & 0 & 0\\\\ 1 & 1 & 0 & 0\\\\ 1 & 0 & 1 & 0\\\\1 & 0 & 1 & 0 \\\\1 & 0 & 0 & 1\\\\1 & 0 & 0 & 1 \\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "\\vec{b} = \\begin{bmatrix} -3 \\\\-1 \\\\0 \\\\2 \\\\5 \\\\1 \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "__Solution__ \n",
    "\n",
    "Let's set up the normal equation for $A\\vec{x} = \\vec{b}$, and find a solution for it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "253f335f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A^TA = \n",
      " [[6 2 2 2]\n",
      " [2 2 0 0]\n",
      " [2 0 2 0]\n",
      " [2 0 0 2]]\n",
      "\n",
      " A^Tb = \n",
      " [[ 4]\n",
      " [-4]\n",
      " [ 2]\n",
      " [ 6]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,1,0,0], [1,1,0,0], [1,0,1,0],[1,0,1,0], [1,0,0,1],[1,0,0,1]])\n",
    "\n",
    "b = np.array([[-3,-1,0,2,5,1]])\n",
    "\n",
    "\n",
    "# compute A^TA\n",
    "ATA = A.T @ A\n",
    "print('A^TA = \\n', ATA)\n",
    "\n",
    "# compute A^Tb\n",
    "ATb = A.T @ b.T\n",
    "print('\\n A^Tb = \\n', ATb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f609e0",
   "metadata": {},
   "source": [
    "Thus, the normal equation is \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 6 & 2 & 2 & 2 \\\\ 2 & 2 & 0 & 0 \\\\ 2 & 0 & 2 & 0 \\\\ 2 & 0 & 0 & 2 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} = \\begin{bmatrix} 4 \\\\ -4 \\\\ 2 \\\\6 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "To solve this equation we form its augmented matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df570e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  2,  2,  2,  4],\n",
       "       [ 2,  2,  0,  0, -4],\n",
       "       [ 2,  0,  2,  0,  2],\n",
       "       [ 2,  0,  0,  2,  6]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aumented \n",
    "M = np.concatenate((ATA, ATb), axis=1)\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902cefd8",
   "metadata": {},
   "source": [
    "Call row operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d997e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap two rows\n",
    "\n",
    "def swap(matrix, row1, row2):\n",
    "    \n",
    "    copy_matrix=np.copy(matrix).astype('float64') \n",
    "  \n",
    "    copy_matrix[row1,:] = matrix[row2,:]\n",
    "    copy_matrix[row2,:] = matrix[row1,:]\n",
    "    \n",
    "    return copy_matrix\n",
    "\n",
    "\n",
    "# Multiple all entries in a row by a nonzero number\n",
    "\n",
    "\n",
    "def scale(matrix, row, scalar):\n",
    "    copy_matrix=np.copy(matrix).astype('float64') \n",
    "    copy_matrix[row,:] = scalar*matrix[row,:]  \n",
    "    return copy_matrix\n",
    "\n",
    "# Replacing a row1 by the sum of itself and a multiple of rpw2 \n",
    "\n",
    "def replace(matrix, row1, row2, scalar):\n",
    "    copy_matrix=np.copy(matrix).astype('float64')\n",
    "    copy_matrix[row1] = matrix[row1]+ scalar * matrix[row2] \n",
    "    return copy_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9ab3288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  0.,  2.,  0.,  2.],\n",
       "       [ 2.,  2.,  0.,  0., -4.],\n",
       "       [ 6.,  2.,  2.,  2.,  4.],\n",
       "       [ 2.,  0.,  0.,  2.,  6.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1 = swap(M, 0, 2)\n",
    "M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef6f7935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  1.],\n",
       "       [ 2.,  2.,  0.,  0., -4.],\n",
       "       [ 6.,  2.,  2.,  2.,  4.],\n",
       "       [ 2.,  0.,  0.,  2.,  6.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2 = scale(M1, 0, 1/2)\n",
    "M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b057f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  1.],\n",
       "       [ 0.,  2., -2.,  0., -6.],\n",
       "       [ 6.,  2.,  2.,  2.,  4.],\n",
       "       [ 2.,  0.,  0.,  2.,  6.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M3 = replace(M2, 1, 0, -2)\n",
    "M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec3acb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  1.],\n",
       "       [ 0.,  2., -2.,  0., -6.],\n",
       "       [ 0.,  2., -4.,  2., -2.],\n",
       "       [ 2.,  0.,  0.,  2.,  6.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M4 = replace(M3, 2, 0, -6)\n",
    "M4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccec84a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  1.],\n",
       "       [ 0.,  2., -2.,  0., -6.],\n",
       "       [ 0.,  2., -4.,  2., -2.],\n",
       "       [ 0.,  0., -2.,  2.,  4.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M5 = replace(M4, 3, 0, -2)\n",
    "M5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cf675c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  1.],\n",
       "       [ 0.,  1., -1.,  0., -3.],\n",
       "       [ 0.,  2., -4.,  2., -2.],\n",
       "       [ 0.,  0., -2.,  2.,  4.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M6 = scale(M5, 1, 1/2)\n",
    "M6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f5dd1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  1.],\n",
       "       [ 0.,  1., -1.,  0., -3.],\n",
       "       [ 0.,  0., -2.,  2.,  4.],\n",
       "       [ 0.,  0., -2.,  2.,  4.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M7 = replace(M6, 2, 1, -2)\n",
    "M7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3984305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  1.],\n",
       "       [ 0.,  1., -1.,  0., -3.],\n",
       "       [-0., -0.,  1., -1., -2.],\n",
       "       [ 0.,  0., -2.,  2.,  4.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M8 = scale(M7, 2, -1/2)\n",
    "M8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b33aa7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  1.],\n",
       "       [ 0.,  1., -1.,  0., -3.],\n",
       "       [-0., -0.,  1., -1., -2.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M9 = replace(M8, 3, 2, 2)\n",
    "M9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7926ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  1.,  3.],\n",
       "       [ 0.,  1., -1.,  0., -3.],\n",
       "       [-0., -0.,  1., -1., -2.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M10 = replace(M9, 0, 2, -1)\n",
    "M10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8594a9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  1.,  3.],\n",
       "       [ 0.,  1.,  0., -1., -5.],\n",
       "       [-0., -0.,  1., -1., -2.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M11 = replace(M10, 1, 2, 1)\n",
    "M11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1b24e5",
   "metadata": {},
   "source": [
    "The general solution is $x_1 = 3 - x_4$, $x_2 = -5 + x_4$, $x_3 = -2 + x_4$, and $x_4$ is a free parameter. So the general least-squares solution of $A\\vec{x} = \\vec{b}$ has the form:\n",
    "\n",
    "$$\n",
    "\\hat{x} = \\begin{bmatrix} 3 \\\\ -5 \\\\ -2 \\\\ 0 \\end{bmatrix} + x_4 \\begin{bmatrix} -1 \\\\ 1 \\\\ 1 \\\\ 0 \\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c9833f",
   "metadata": {},
   "source": [
    "Any linear system $A\\vec{x} = \\vec{b}$ admits at least one least-squares solution (the orthogonal projection $\\hat{b}$). For example, the least-squares solution of $A\\vec{x} = \\vec{b}$ in Example 1 was unique, while the linear system in Example 2 has infinitely many least-squares solutions.\n",
    "\n",
    "The next theorem gives useful criteria for determining when there is only one least-squares solution.\n",
    "\n",
    "`````{admonition} Theorem 10\n",
    ":class: tip\n",
    "\n",
    "Let $A$ be an $m\\times n$ matrix. The following statements are equivalent:\n",
    "\n",
    "   1. The equation $A\\vec{x} = \\vec{b}$ has a unique least-squares solution for each $\\vec{b}\\in \\mathbb{R}^n$.\n",
    "   \n",
    "   2. The columns of $A$ are linearly independent.\n",
    "   \n",
    "   3. The matrix $A^TA$ is invertible.\n",
    "   \n",
    "   \n",
    "In any of these cases, the least-squares solution $\\hat{x}$ is given by:\n",
    "\n",
    "$$\n",
    "\\hat{x} = (A^TA)^{-1} A^T \\vec{b}.\n",
    "$$\n",
    "\n",
    "Moreover, if $A = QR$ is a $QR$-factorization of $A$, then the least-squares solution $\\hat{x}$ is given by:\n",
    "\n",
    "$$\n",
    "\\hat{x} = R^{-1} Q^{T} \\vec{b}. \\quad (*)\n",
    "$$\n",
    "\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e9e809",
   "metadata": {},
   "source": [
    "```{admonition} Example 3\n",
    "\n",
    "Let $A = \\begin{bmatrix} 1 & 3 & 5 \\\\ 1 & 1 & 0 \\\\ 1 & 1 & 2 \\\\ 1 & 3 & 3\\end{bmatrix}$ and $\\vec{b} = \\begin{bmatrix} 3 \\\\ 5 \\\\ 7 \\\\ -3 \\end{bmatrix}$. Find a least-squares solution of $A\\vec{x} = \\vec{b}$.\n",
    "```\n",
    "\n",
    "__Solution:__\n",
    "\n",
    "A QR-factorization of $A$ can be obtained as in Section 5.3 using `numpy.linalg.qr()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b0015a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q = \n",
      " [[-0.5  0.5 -0.5]\n",
      " [-0.5 -0.5  0.5]\n",
      " [-0.5 -0.5 -0.5]\n",
      " [-0.5  0.5  0.5]] \n",
      "\n",
      "R = \n",
      " [[-2. -4. -5.]\n",
      " [ 0.  2.  3.]\n",
      " [ 0.  0. -2.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,3,5], [1,1,0], [1,1,2],[1,3,3]])\n",
    "\n",
    "# QR factorization\n",
    "\n",
    "Q, R = np.linalg.qr(A)\n",
    "\n",
    "print('Q = \\n', Q, '\\n')\n",
    "\n",
    "print('R = \\n', R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe32f48",
   "metadata": {},
   "source": [
    "Now we compute  $\\hat{x} = R^{-1} Q^{T} \\vec{b}:$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa05df6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.],\n",
       "       [-6.],\n",
       "       [ 2.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup\n",
    "b = np.array([[3, 5, 7, -3]]).T\n",
    "\n",
    "#computing x_hat\n",
    "\n",
    "x_hat = np.linalg.inv(R) @ Q.T @ b\n",
    "x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b749f0a",
   "metadata": {},
   "source": [
    "### Numerical Note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1932b2ba",
   "metadata": {},
   "source": [
    "Since $R$ in $(*)$ is an upper triangular matrix, we can alternatively compute $\\hat{x}$ by finding the exact solutions of:\n",
    "\n",
    "$$\n",
    "R\\hat{x} = Q^{T} \\vec{b}. \\quad (**)\n",
    "$$\n",
    "\n",
    "For large matrices, solving $(**)$ by back-substitution or row operations is faster than computing $R^{-1}$ and using $(*)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbc54a9",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8888ad",
   "metadata": {},
   "source": [
    "```{admonition}{Exercises}\n",
    "1. Let \n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix} 1 & -3 & -3 \\\\  1 & 5 & 1 \\\\ 1 & 1 & 2 \\\\ 1 & 7 & 2\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "\\vec{b} = \\begin{bmatrix} 5 \\\\ -3 \\\\ -5 \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "\n",
    "    a.  Find a least-squares solution of $A\\vec{x} = \\vec{b}$.\n",
    "    \n",
    "    b. Compute the associated least-squares error $\\| \\vec{b} - A\\hat{x}\\|$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. Describe all least-squares solutions of the system\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    x + y &= 2 \\\\ \n",
    "    x + y &= 4 \\\\ \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
