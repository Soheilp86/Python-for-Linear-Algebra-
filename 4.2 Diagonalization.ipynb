{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf3a9aae",
   "metadata": {},
   "source": [
    "# 4.2 Diagonalization\n",
    "\n",
    "This section introduces diagonalization and characterizes diagonalizability. Diagonalization is a useful factorization of a matrix $A$ based on its eigenvalue–eigenvector information. This factorization allows us to quickly access properties that are invariant under similarity, such as rank, invertibility, and eigenvalues. It also enables us to calculate powers of $A$ for large $k$, which is a fundamental concept in various applications, including discrete dynamical systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b79d0",
   "metadata": {},
   "source": [
    "## Computing powers of a matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ced4754",
   "metadata": {},
   "source": [
    "Let's consider the matrix $A = \\begin{bmatrix} 7 & 2\\\\ -4 & 1 \\end{bmatrix}$. We wish to compute $A^{k}$ for an arbitrary $k\\in \\mathbb{N}$, given that $A= PAP^{-1}$, where $P = \\begin{bmatrix} 1 & 1\\\\ -1 & -2 \\end{bmatrix}$, and $D = \\begin{bmatrix} 5 & 0\\\\ 0 & 3 \\end{bmatrix}$.\n",
    "\n",
    "Using this decomposition, we have:\n",
    "\n",
    "$$\n",
    "A^{k} = (PDP^{-1})(PDP^{-1})\\dots (PDP^{-1}) = PD^{k}P.\n",
    "$$\n",
    "\n",
    "Since $D$ is diagonal, $D^{k} = \\begin{bmatrix} 5^{k} & 0\\\\ 0 & 3^{k} \\end{bmatrix}$. Additionally, $P^{-1} = \\begin{bmatrix} 2 & 1\\\\ -1 & -1 \\end{bmatrix}$. Therefore,\n",
    "\n",
    "$$\n",
    "A^{k} = \\begin{bmatrix} 1 & 1\\\\ -1 & -2 \\end{bmatrix} \\begin{bmatrix} 5^{k} & 0\\\\ 0 & 3^{k}\\end{bmatrix} \\begin{bmatrix} 2 & 1\\\\ -1 & -1 \\end{bmatrix} = \\begin{bmatrix}  2\\times 5^{k} -3^{k}& 5^{k}- 3^{k}\\\\ 2\\times 3^{k} - 2\\times 5^{k} & 2 \\times3^{k} -5^{k}\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "This decomposition, known as diagonalization, enables us to compute $A^k$ easily for large values of $k$. Without such factorization, computing $A^k$ for large matrices and large $k$ can be a time-consuming task. Therefore, it is beneficial to find such decomposition before calculating the power of $A$. \n",
    "\n",
    "Unfortunately, this decomposition doesn't exist for all matrices. The goal of this section is to characterize matrices that admit such a factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a095cbb",
   "metadata": {},
   "source": [
    "## Diagonalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5293f9f7",
   "metadata": {},
   "source": [
    "An $n \\times n$ matrix $A$ is called __diagonalizable__ if it is _similar_ to a diagonal matrix. More precisely, there exists an invertible $n \\times n$ matrix $P$ and an $n \\times n$ diagonal matrix $D$ such that $A = PDP^{-1}$.\n",
    "\n",
    "It turns out an $n\\times n$ matrix is diagonalizable if we can form a basis $\\mathbb{R}^n$ using eigenvectors of $A$:\n",
    "\n",
    "__Theorem 1__\n",
    "\n",
    "An $n \\times n$ matrix $A$ is diagonalizable if and only if $A$ has $n$ linearly independent eigenvectors.\n",
    "\n",
    "\n",
    "In fact, suppose $\\lambda_1, \\lambda_2, \\dots, \\lambda_n$ are eigenvalues of $A$, and $\\{\\vec{v_1}, \\vec{v}_2, \\dots, \\vec{v}_n\\}$ is the linearly independent set of eigenvectors of $A$. If we form the matrix $P$ by taking the eigenvectors as columns, and $D$ is a diagonal matrix with eigenvalues $\\lambda_1, \\lambda_2, \\dots, \\lambda_n$ on the diagonal, then we have $A = PDP^{-1}$.\n",
    "\n",
    "\n",
    "Finding eigenvectors in general is not an easy task, and is not clear how to check which $n \\times n$ matrices have $n$ linearly independent eigenvectors. The next theorem partially addresses this issue.\n",
    "\n",
    "\n",
    "__Theorem 2__\n",
    "\n",
    "The eigenvectors corresponding to distinct eigenvalues are linearly independent.\n",
    "\n",
    "Combining Theorem 1 and Theorem 2, we obtain the following corollary:\n",
    "\n",
    "__Corollary 1__\n",
    "\n",
    "An $n \\times n$ matrix with $n$ distinct eigenvalues is diagonalizable.\n",
    "\n",
    "\n",
    "\n",
    "__Example 1__  Is\n",
    "$\n",
    "A = \\begin{bmatrix} 1 & 3 & 2 \\\\ -3 & -5 & 3 \\\\ 3 & 3 & 1 \\end{bmatrix}\n",
    "$\n",
    "diagonalizable? If yes find a diagonalization for it. \n",
    "\n",
    "__Solution__\n",
    "\n",
    "To determine if $A$ is diagonalizable we need to find eigenvalues and to check if it admits $3$ linearly independent eigenvectors. \n",
    "\n",
    "- Step 1 \n",
    "\n",
    "we use _linalg.eigvas_ to find the eigenvalues and eigenvectors of $A$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15bb8c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues =  [-5. -2.  4.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg\n",
    "\n",
    "A = np.array([[1,3,3],[-3,-5,3],[3,3,1]])\n",
    "# find evalues and evectors\n",
    "evalues, evectors = linalg.eig(A)\n",
    "\n",
    "print(\"eigenvalues = \",  evalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6023aa",
   "metadata": {},
   "source": [
    "$A$ has three distintc eigenvalues and therefore it is diagonalizable by Corollary 1.\n",
    "\n",
    "- Step 2: Constructing the diagonal matrix $D$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be0c7748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.,  0.,  0.],\n",
       "       [ 0., -2.,  0.],\n",
       "       [ 0.,  0.,  4.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_1 = evalues[0]\n",
    "lambda_2 = evalues[1]\n",
    "lambda_3 = evalues[2]\n",
    "\n",
    "D = np.array([[lambda_1, 0, 0], [0, lambda_2, 0], [0, 0, lambda_3]]) \n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ebbc4f",
   "metadata": {},
   "source": [
    "- Step 3 : Finding the matrix $P$ whose $i$th column is an eigenvector corresponding to $\\lambda_{i}$ for $i\\in \\{1,\\ 2,\\ 3\\}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ad8506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the invirtible matrix P\n",
    "P = evectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2ed366",
   "metadata": {},
   "source": [
    "- Step 4: compute the inverse of matrix P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08ef321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the inverse of P\n",
    "\n",
    "Q = linalg.inv(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d9fb77",
   "metadata": {},
   "source": [
    "- Step 5 (sanity check): Now that we have $D$, $P$, $Q = P^{-1}$, lets check if $A = PDQ$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3d28534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  3.,  3.],\n",
       "       [-3., -5.,  3.],\n",
       "       [ 3.,  3.,  1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P @ D @ Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f245bf85",
   "metadata": {},
   "source": [
    "__Example 2__  Is\n",
    "$\n",
    "A = \\begin{bmatrix} 1 & 3 & 2 \\\\ -3 & -5 & -3 \\\\ 3 & 3 & 1 \\end{bmatrix}\n",
    "$\n",
    "diagonalizable? If yes find a diagonalization for it. \n",
    "\n",
    "__Solution:__ \n",
    "\n",
    "- Step 1:  Finding eigenvalues and eigenvectors of $A$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "635d03ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues =  [ 1. -2. -2.]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,3,3],[-3,-5,-3],[3,3,1]])\n",
    "\n",
    "# find evalues and evectors\n",
    "evalues, evectors = linalg.eig(A)\n",
    "\n",
    "print(\"eigenvalues = \",  evalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a46e60",
   "metadata": {},
   "source": [
    "$A$ has 2 eigenvalues: $\\lambda_1 = 1$ with multiplicity 1 and $\\lambda_2 = -2$ with multiplicity 2. Note that we cannot use Corollary 1 anymore because eigenvalues are not distinct. To check if $A$ is diagonalizable, we need to find three linearly independet eigenvectors of $A$. Lets have a look at our eigenvectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f922fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A matrix whose columns are eigenvectors:\n",
    "P = evectors\n",
    "\n",
    "# computes the rank of P\n",
    "np.linalg.matrix_rank(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246318c7",
   "metadata": {},
   "source": [
    "Since $rank(P) = 3$ the columns of $P$ are linearly independents. Thus, $A$ is diagonalizable by Theorem 1. \n",
    "\n",
    "- Step 2: Finding the diagonal matrix $D$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4528af93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 0., -2.,  0.],\n",
       "       [ 0.,  0., -2.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_1 = evalues[0]\n",
    "lambda_2 = evalues[1]\n",
    "lambda_3 = evalues[2]\n",
    "\n",
    "D = np.array([[lambda_1, 0, 0], [0, lambda_2, 0], [0, 0, lambda_3]]) \n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d6f25",
   "metadata": {},
   "source": [
    "- Step 3: Finding the matrix $P$ whose $i$th column is an eigenvector corresponding to $\\lambda_{i}$ for $i\\in \\{1,\\ 2,\\ 3\\}$. We already have this matrix so we go to the next step.\n",
    "\n",
    "- Step 4: Computing the inverse of $P$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85aa5e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.73205081,  1.73205081,  1.73205081],\n",
       "       [-1.41421356, -1.2786323 ,  0.13558127],\n",
       "       [ 0.        ,  1.48664829,  1.48664829]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing the inverse of P\n",
    "\n",
    "Q = np.linalg.inv(P)\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516675d1",
   "metadata": {},
   "source": [
    "- Step 5 (sanity check): lets check if $A = PDQ$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15aa69ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  3.,  3.],\n",
       "       [-3., -5., -3.],\n",
       "       [ 3.,  3.,  1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check A = PDQ \n",
    "P @ D @ Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64623211",
   "metadata": {},
   "source": [
    "The next theorem provides another way to characterize the diagonalizability of matrices based on the multiplicity of eigenvalues. Before stating the theorem, we need the following definition:\n",
    "\n",
    "Suppose $A$ is a square matrix and $\\lambda$ is an eigenvalue of $A$. The dimension of the corresponding eigenspace $E_{\\lambda} = null(A -\\lambda I)$ is called the __geometric multiplicity of $\\lambda$__.\n",
    "\n",
    "__Theorem 3:__\n",
    "\n",
    "A square matrix $A$ is diagonalizable if and only if the algebraic multiplicity of each eigenvalue is equal to its geometric multiplicity. More formally, if $\\lambda_1, \\lambda_2, \\dots, \\lambda_p$ are eigenvalues of $A$ with algebraic multiplicities $m_1, m_2, \\dots, m_p$, respectively, then \n",
    "\n",
    "$$\n",
    "m_i = \\text{dim}(E_{\\lambda_i}) \\quad \\forall i \\in \\{1, 2, \\dots, p\\}\n",
    "$$\n",
    "\n",
    "Recall that dim($E_{\\lambda_i}$) = dim null$(A-\\lambda_i I)$ = the number of non-pivot columns in $(A-\\lambda_{i} I)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc27c5a",
   "metadata": {},
   "source": [
    "__Example 3:__ \n",
    "\n",
    "Is $M = \\begin{bmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 1 \\\\ 0 & 0 & 2 \\end{bmatrix}$ diagonalizable? If yes, find a diagonalization for it.\n",
    "\n",
    "__Solution:__\n",
    "\n",
    "$M$ is an upper triangular matrix, and its eigenvalues are on the diagonal: $\\lambda_1 = 1$ with algebraic multiplicity 2 and $\\lambda_2 = 2$ with algebraic multiplicity 1.\n",
    "\n",
    "Since we don't have distinct eigenvalues, Corollary 1 doesn't apply here. Let's take a look at our eigenvectors:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18c63656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg\n",
    "\n",
    "\n",
    "M = np.array([[1, 1, 0], [0, 1, 1], [0, 0, 2]])\n",
    "\n",
    "evalues, evectors  = np.linalg.eig(M)\n",
    "p = evectors\n",
    "\n",
    "np.linalg.matrix_rank(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e95c7",
   "metadata": {},
   "source": [
    "Observe that the rank of matrix $P$ is two, which means we don't have three linearly independent eigenvectors in $M$. However, using Theorem 3, we can confirm that this is not the case, and consequently, $M$ is not diagonalizable. In fact, it is straightforward to check that the geometric multiplicity of $\\lambda = 1$ is 1 ($\\text{dim}(E_1) = 1$), while the algebraic multiplicity is 2. Thus, $M$ is not diagonalizable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a937ea7c",
   "metadata": {},
   "source": [
    "## Diagonalization as a change of basis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc627d0",
   "metadata": {},
   "source": [
    "Recall that similar matrices represent the same linear map under two different choices of a pair of bases for $\\mathbb{R}^n$ and $\\mathbb{R}^m$. More precisely, suppose $A = PCP^{-1}$ ($C$ is not necessarily diagonal), then the matrix representation of $T$ with respect to the basis $B$ (formed by the columns of $P$) is $C$. Conversely, changing the basis of $\\mathbb{R}^n$ leads to a matrix representation of $T$ that is similar to $A$ (section 3.4). This particularly applies to diagonalizable matrices because a matrix is diagonalizable if it is similar to a diagonal matrix.\n",
    "\n",
    "__Theorem 2__ (Diagonal Matrix Representation)\n",
    "\n",
    "Suppose $T: \\mathbb{R}^n \\to \\mathbb{R}^n$ and $A$ is the standard matrix representation of $T$ that is diagonalizable. Let $A = PDP^{-1}$ be a diagonalization of $A$ where $D$ is an $n\\times n$ diagonal matrix, and $P$ is an invertible $n\\times n$ matrix. If $B$ is the basis for $\\mathbb{R}^n$ formed by the columns of $P$, then $D$ is the matrix representation of the transformation $T: (\\mathbb{R}^n, B) \\to (\\mathbb{R}^n, B)$.\n",
    "\n",
    "__Example 3__ Let $T: \\mathbb{R}^2 \\to \\mathbb{R}^2$ and $A = \\begin{bmatrix} 7 & 2 \\\\ -4 & 2 \\end{bmatrix}$ be the standard matrix representation of $T$. Find a basis $B$ for $T$ such that the matrix representation of $T$ with respect to $B$ is diagonal.\n",
    "\n",
    "__Solution:__\n",
    "\n",
    "From Example 1, we know that $A = PAP^{-1}$ where $P = \\begin{bmatrix} 1 & 1 \\\\ -1 & -2 \\end{bmatrix}$ and $D = \\begin{bmatrix} 5 & 0 \\\\ 0 & 3 \\end{bmatrix}$.\n",
    "\n",
    "The columns of $P$ are eigenvectors of $A$, and they form a basis $B$ for $\\mathbb{R}^2$. By Theorem 2, $D$ is the matrix representation of $T$ with respect to $B$. In fact, the mappings $\\vec{x} \\to A\\vec{x}$ and $\\vec{x} \\to D\\vec{x}$ describe the same linear transformation, relative to different bases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83044220",
   "metadata": {},
   "source": [
    "## Excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c7480b",
   "metadata": {},
   "source": [
    "\n",
    "1. Suppose\n",
    "$\n",
    "M = \\begin{bmatrix} 2 & 4 & 3 \\\\ -4 & -6 & -3 \\\\ 3 & 3 & 1 \\end{bmatrix}.\n",
    "$\n",
    "\n",
    "    a. Is M diagonalizable? If yes find a diagonalization for it.\n",
    "    \n",
    "    b. Use this diagonalization to compute $M^{100}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. Suppose $C=\\begin{bmatrix}\n",
    "3 & 0 & 1 & 0 & 0\\\\\n",
    "0 & 3 & 0 & 0 & 0\\\\\n",
    "0 & 0 & 3 & 0 & 0\\\\\n",
    "0 & 0 & 3 & 2 & 0\\\\\n",
    "0 & 0 & 0 & 0 & 2\n",
    "\\end{bmatrix}$. Is $C$ diagonalizable?\n",
    "\n",
    "\n",
    "3. Let $A$ be a $5\\times 5$ matrix, with two eigenvalues. One eigenspace is three-dimensional, the other is two dimensional. Is $A$ diagonalizable?\n",
    "\n",
    "\n",
    "4. Compute $A^{200}$ where $A = \\begin{bmatrix} 4 & -3\\\\ 2 & -1 \\end{bmatrix}$. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
